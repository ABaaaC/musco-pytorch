{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import copy\n",
    "import imp\n",
    "import numpy as np\n",
    "\n",
    "from sktensor  import dtensor, ktensor, cp_als\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "gpu = 0\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from model_utils import load_model, DATA_ROOT, SAVE_ROOT\n",
    "\n",
    "MODEL_NAME = 'vgg16_imagenet'\n",
    "# MODEL_NAME = 'resnet50_imagenet'\n",
    "\n",
    "model = load_model(MODEL_NAME)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BTD layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using numpy backend.\n",
      "Using pytorch backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from tensor_compression.compress import btd2_init_random, btd2_als, btd1_init_random, btd1_als \n",
    "\n",
    "class BTDTucker2DecomposedLayer(nn.Module):\n",
    "    def __init__(self,  layer, layer_name, tucker_ranks = None):\n",
    "        super(BTDTucker2DecomposedLayer, self).__init__()\n",
    "        self.tucker_ranks = tucker_ranks\n",
    "        self.btd_rank = len(self.tucker_ranks[0])\n",
    "        \n",
    "        self.layer_name = layer_name\n",
    "        \n",
    "        if layer._get_name() != 'Conv2d':\n",
    "            raise AttributeError('only convolution layer can be decomposed')\n",
    "        self.cin = layer.in_channels\n",
    "        self.cout = layer.out_channels\n",
    "\n",
    "        self.kernel_size = layer.kernel_size\n",
    "        self.padding = layer.padding\n",
    "        self.stride = layer.stride\n",
    "        print('cin : {}, cout : {}, kernel : {}'.format(self.cin, self.cout, self.kernel_size))\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.weight = layer.weight.data\n",
    "        self.weight = self.weight.reshape(*self.weight.shape[:2], -1)\n",
    "        try:\n",
    "            self.bias = layer.bias.data\n",
    "        except:\n",
    "            self.bias = None\n",
    "        \n",
    "        print('Create..............')\n",
    "        self.create_decomposed_layers()\n",
    "        \n",
    "        print('Initialize...........')\n",
    "        self.iniialize_decomposed_layers()\n",
    "     \n",
    "        self.weight = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def create_decomposed_layers(self):\n",
    "        for k in range(self.btd_rank):\n",
    "            branch = nn.Sequential()\n",
    "            for j, l in enumerate(self.create_branch(k)):\n",
    "                branch.add_module('{}'.format(j), l)\n",
    "            \n",
    "            self.add_module('{}-{}'.format(self.layer_name, k), branch)\n",
    "        \n",
    "        self.add_module('{}-{}'.format(self.layer_name, k+1), nn.ReLU(inplace = True))\n",
    "\n",
    "            \n",
    "    def iniialize_decomposed_layers(self):\n",
    "        for k, (weights, biases) in enumerate(list(zip(*self.get_factors()))):\n",
    "        \n",
    "            for j, (w, b)  in enumerate(zip(weights, biases)):\n",
    "                self.__getattr__('{}-{}'.format(self.layer_name, k)).__getattr__('{}'.format(j)).weight.data = w\n",
    "               \n",
    "                if b is not None:\n",
    "                    self.__getattr__('{}-{}'.format(self.layer_name, k)).__getattr__('{}'.format(j)).bias.data = b\n",
    "                else:\n",
    "                    self.__getattr__('{}-{}'.format(self.layer_name, k)).__getattr__('{}'.format(j)).bias = None \n",
    "\n",
    "    \n",
    "#     def get_weights_to_decompose(self):\n",
    "#         weight = layer.weight.data\n",
    "#         weight = weight.reshape(*weight.shape[:2], -1)\n",
    "#         try:\n",
    "#             bias = layer.bias.data\n",
    "#         except:\n",
    "#             bias = None\n",
    "#         return weight, bias\n",
    "        \n",
    "        \n",
    "    def get_factors(self):\n",
    "        bias = self.bias\n",
    "        \n",
    "        cores, As, Bs = btd2_init_random(self.weight.shape, self.tucker_ranks)\n",
    "        guess = [cores, As, Bs]\n",
    "        cores, As, Bs = btd2_als(self.weight, guess, return_fit = False)\n",
    "        \n",
    "      \n",
    "        cores  = [core.numpy() for core in cores]\n",
    "        As = [A.numpy() for A in As]\n",
    "        Bs = [B.numpy() for B in Bs]\n",
    "        \n",
    "        for k, (core, A, B) in enumerate(zip(cores, As, Bs)):\n",
    "            print('k = {}, core: {}, A : {}, B : {}'.format(k, core.shape, A.shape, B.shape))\n",
    "        \n",
    "        w_cins = []\n",
    "        w_cores = []\n",
    "        w_couts = []\n",
    "        \n",
    "        for k in range(self.btd_rank):\n",
    "            w_cin = torch.FloatTensor(np.reshape(Bs[k].T,\n",
    "                                                 [self.tucker_ranks[k][1], self.cin, 1, 1])).contiguous()\n",
    "            w_core = torch.FloatTensor(np.reshape(cores[k],\n",
    "                                                  [self.tucker_ranks[k][0], self.tucker_ranks[k][1], *self.kernel_size])).contiguous()\n",
    "            w_cout = torch.FloatTensor(np.reshape(As[k], [self.cout, self.tucker_ranks[k][0], 1, 1])).contiguous()\n",
    "            \n",
    "            w_cins.append(w_cin)\n",
    "            w_cores.append(w_core)\n",
    "            w_couts.append(w_cout)\n",
    "            \n",
    "        \n",
    "        biases  = [[None, None,  None]]*(self.btd_rank-1) + [[None, None,  bias]]\n",
    "        \n",
    "        return list(zip(*[w_cins, w_cores, w_couts])),  biases\n",
    "    \n",
    "    \n",
    "    def create_branch(self, k):\n",
    "        layers = [] \n",
    "        layers.append(nn.Conv2d(in_channels=self.cin,\n",
    "                                    out_channels=self.tucker_ranks[k][1],\n",
    "                                    kernel_size = (1, 1)))\n",
    "\n",
    "        layers.append(nn.Conv2d(in_channels = self.tucker_ranks[k][1], \n",
    "                                    out_channels=self.tucker_ranks[k][0],\n",
    "                                    kernel_size = self.kernel_size,\n",
    "                                    groups = 1, \n",
    "                                    padding = self.padding,\n",
    "                                    stride = self.stride))\n",
    "\n",
    "        layers.append(nn.Conv2d(in_channels = self.tucker_ranks[k][0],\n",
    "                                    out_channels = self.cout, \n",
    "                                    kernel_size = (1, 1)))\n",
    "        return layers\n",
    "    \n",
    "    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i,l in enumerate(list(self.children())[:-1]):\n",
    "            if i == 0:\n",
    "                out = l(x)\n",
    "            else:\n",
    "                out += l(x)\n",
    "        \n",
    "        out = list(self.children())[-1](out)\n",
    "        \n",
    "        x = out\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6, 2), (8, 4)]\n",
      "cin : 64, cout : 128, kernel : (3, 3)\n",
      "Create..............\n",
      "Initialize...........\n",
      "k = 0, core: (6, 2, 9), A : (128, 6), B : (64, 2)\n",
      "k = 1, core: (8, 4, 9), A : (128, 8), B : (64, 4)\n"
     ]
    }
   ],
   "source": [
    "layer_name = '5'\n",
    "layer = model.features.__getattr__(layer_name)\n",
    "\n",
    "R1 = [6, 8]\n",
    "R2 = [2, 4]\n",
    "R = list(zip(R1, R2))\n",
    "print(R)\n",
    "\n",
    "\n",
    "module_name = 'features'\n",
    "decomposed_layer = BTDTucker2DecomposedLayer(model.__getattr__(module_name).__getattr__(layer_name),\n",
    "                                               layer_name, R)\n",
    "\n",
    "compressed_model = copy.deepcopy(model)\n",
    "compressed_model.__getattr__(module_name).__setattr__(layer_name, decomposed_layer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): BTDTucker2DecomposedLayer(\n",
       "      (5-0): Sequential(\n",
       "        (0): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): Conv2d(2, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): Conv2d(6, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (5-1): Sequential(\n",
       "        (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (5-2): ReLU(inplace)\n",
       "    )\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building imagenet data loader with 0 workers\n"
     ]
    }
   ],
   "source": [
    "# Choose from 'mnist', 'cifar10', 'imagenet'\n",
    "DATASET = 'imagenet'\n",
    "\n",
    "##### Load data\n",
    "import dataloaders\n",
    "\n",
    "bs = 8\n",
    "\n",
    "loaders = dataloaders.get_loader(bs, DATASET, DATA_ROOT, num_workers = 0, simple_normalize=True)\n",
    "test_loader = loaders['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 224, 224])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = dataloaders.get_batch(test_loader)\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.7639,  4.6316,  3.2578,  ..., -2.6185,  1.8284,  2.0557],\n",
       "        [-0.4243,  0.7162,  3.1696,  ..., -3.1432,  0.3533,  1.0447],\n",
       "        [ 0.1949,  0.8280, -0.3820,  ..., -2.8338,  1.8218,  4.0224],\n",
       "        ...,\n",
       "        [-0.8698,  0.3646,  1.2397,  ..., -2.1741,  2.7798,  1.5710],\n",
       "        [-1.5034,  0.5579,  1.0676,  ..., -4.8371, -0.3656, -0.6902],\n",
       "        [ 2.7631,  3.4931,  3.3120,  ..., -3.7741,  0.6654,  0.8105]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
