{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from model_utils import load_model\n",
    "\n",
    "MODEL_NAME = 'vgg16_imagenet'\n",
    "# MODEL_NAME = 'resnet50_imagenet'\n",
    "# MODEL_NAME = 'resnet18_imagenet'\n",
    "\n",
    "# MODEL_NAME = 'faster_rcnn_vgg16\n",
    "# MODEL_NAME = 'faster_rcnn_resnet50'\n",
    "\n",
    "\n",
    "# # Uncomment if MODEL_NAME = 'faster_rcnn_resnet50'\n",
    "# sys.path.append('/workspace/home/jgusak/maxvol_objects/facebook_frcnn/')\n",
    "# import maskrcnn_benchmark\n",
    "\n",
    "model = load_model(MODEL_NAME)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get  all  layers\n",
    "\n",
    "Function  **get_layer_names()** returns names of model layers (convolutional and fully connected) and boolean mask for convolutional layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['features.0' 'features.2' 'features.5' 'features.7' 'features.10'\n",
      " 'features.12' 'features.14' 'features.17' 'features.19' 'features.21'\n",
      " 'features.24' 'features.26' 'features.28']\n",
      "['classifier.0' 'classifier.3' 'classifier.6']\n"
     ]
    }
   ],
   "source": [
    "from model_utils import get_layer_names\n",
    "\n",
    "layer_names, conv_layer_mask = get_layer_names(model)\n",
    "\n",
    "fc_layer_mask = (1 - conv_layer_mask).astype(bool)\n",
    "\n",
    "print(layer_names[conv_layer_mask])\n",
    "print(layer_names[fc_layer_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary function\n",
    "import numpy as np\n",
    "def split_resnet_layers_by_blocks(lnames):\n",
    "    starts = ['body.stem.conv1'] + ['body.layer{}'.format(i) for i in range(1,5)]\n",
    "\n",
    "    start_idx = 0\n",
    "    blocks_idxs = []\n",
    "    layer_names_by_blocks = []\n",
    "\n",
    "    for s in starts:\n",
    "        curr_block =  [l for l in lnames if l.startswith(s)]\n",
    "        layer_names_by_blocks.append(curr_block)\n",
    "\n",
    "        blocks_idxs.append(np.arange(start_idx, start_idx+len(curr_block)))\n",
    "        start_idx += len(curr_block)\n",
    "\n",
    "    return blocks_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compress selected layers\n",
    "\n",
    "For **convolutional** layers\n",
    "- Set **decomposition**: 'tucker2', 'cp3' or 'cp4'\n",
    "- Set  decomposition **ranks** for convolutional layers (namely, ranks we use to decompose convolutional weight tensors). \n",
    "  - In Tucker2 case, for one layer \n",
    "      - If **rank = None**, the layer won't be decomposed.\n",
    "      - Elif **rank = 0**, then  VBMF method with **vbmf_weaken_factor**  will be used to select (rank_cout, rank_cin).\n",
    "      - Elif **rank = (-scalar) < 0**, then values (rank_cout, rank_cin) will be choosen as maximal values which allow **(sacalar x) layer parameter reduction**.\n",
    "      - Else **rank = tuple** and determines absolute ranks values (rank_cout, rank_cin)\n",
    "  - In CP case, rank for one layer is a scalar\n",
    "      - If **rank = None**, the layer won't be decomposed.\n",
    "      - Elif **rank = (-scalar) < 0** then value for rank will be choosen as maximal rank which allows **(sacalar x) layer parameter reduction**.\n",
    "      - Else **rank = scalar > 0** and determines absolute rank value.\n",
    "      \n",
    "For **fully connected** layers\n",
    "- Set **decomposition** = 'svd'\n",
    "- Set decomposition for linear layers (namely, ranks we use to factorize weight matrices)\n",
    "    - In SVD case, rank for one layer is a scalar\n",
    "      - If **rank = None**, the layer won't be decomposed.\n",
    "      - Elif **rank = 0**, then  VBMF method with **vbmf_weaken_factor**  will be used to select rank.\n",
    "      - Elif **rank = (-scalar) < 0** then value for rank will be choosen as maximal rank which allows **(sacalar x) layer parameter reduction**.\n",
    "      - Else **rank = scalar > 0** and determines absolute rank value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor_compression import get_compressed_model\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "# decomposition_conv = 'cp4'\n",
    "decomposition_conv = 'cp3'\n",
    "# decomposition_conv = 'tucker2'\n",
    "\n",
    "decomposition_fc = 'svd'\n",
    "\n",
    "# RANK_SELECTION = 'vbmf'\n",
    "RANK_SELECTION = 'nx'\n",
    "# RANK_SELECTION = 'custom'\n",
    "\n",
    "if RANK_SELECTION == 'vbmf':\n",
    "    WEAKEN_FACTOR = 1.\n",
    "    X_FACTOR = 0\n",
    "    rank_selection_suffix = \"/wf:{}\".format(WEAKEN_FACTOR)\n",
    "elif RANK_SELECTION == 'nx':\n",
    "    WEAKEN_FACTOR = None  \n",
    "    X_FACTOR = 20\n",
    "    rank_selection_suffix = \"/{}x\".format(X_FACTOR)\n",
    "    \n",
    "    \n",
    "if MODEL_NAME == 'vgg16_imagenet':\n",
    "    ranks_conv = [None] + [-X_FACTOR]*(len(layer_names[conv_layer_mask])-1)\n",
    "    ranks_fc = [-X_FACTOR]*(len(layer_names[fc_layer_mask]))\n",
    "elif MODEL_NAME == 'resnet50_imagenet':\n",
    "    ranks_conv = [None if not name.endswith('conv2') else -X_FACTOR\n",
    "                  for name in layer_names[conv_layer_mask]]\n",
    "    ranks_fc = [-X_FACTOR]*(len(layer_names[fc_layer_mask]))\n",
    "elif MODEL_NAME == 'resnet18_imagenet':\n",
    "    ranks_conv = [None if name == 'conv1' or not (name.endswith('conv2') or\n",
    "                                                  name.endswith('conv1')) else -X_FACTOR\n",
    "              for name in layer_names[conv_layer_mask]]\n",
    "    ranks_fc = [-X_FACTOR]*(len(layer_names[fc_layer_mask]))\n",
    "elif MODEL_NAME ==  'faster_rcnn_resnet50':\n",
    "    ranks_conv = [None if not name.endswith('body.conv2') else -X_FACTOR\n",
    "                  for name in layer_names[conv_layer_mask]]\n",
    "    ranks_fc = [-X_FACTOR]*(len(layer_names[fc_layer_mask]))\n",
    "    \n",
    "    \n",
    "\n",
    "ranks = np.array([None]*len(layer_names))\n",
    "ranks[conv_layer_mask] = ranks_conv\n",
    "ranks[fc_layer_mask] = ranks_fc\n",
    "\n",
    "decompositions = np.array([None]*len(layer_names))\n",
    "decompositions[conv_layer_mask] = decomposition_conv\n",
    "decompositions[fc_layer_mask] = decomposition_fc\n",
    "\n",
    "CONV_SPLIT = 3\n",
    "FC_SPLIT = 1\n",
    "n_layers = len(layer_names)\n",
    "\n",
    "RESNET_SPLIT = False\n",
    "if MODEL_NAME in ['resnet50_imagenet', 'resnet18_imagenet',  'faster_rcnn_resnet50'] and RESNET_SPLIT:\n",
    "    split_tuples = split_resnet_layers_by_blocks(layer_names[conv_layer_mask])[::-1]\n",
    "else:\n",
    "    split_tuples = np.array_split(np.arange(n_layers)[conv_layer_mask], CONV_SPLIT)[::-1]\n",
    "split_tuples.append(np.array_split(np.arange(n_layers)[fc_layer_mask], FC_SPLIT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 9, 10, 11, 12]),\n",
       " array([5, 6, 7, 8]),\n",
       " array([0, 1, 2, 3, 4]),\n",
       " [array([13, 14, 15])]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['features.21' 'features.24' 'features.26' 'features.28'] [-20 -20 -20 -20]\n",
      "Decompose layer features.21\n"
     ]
    }
   ],
   "source": [
    "compressed_model = copy.deepcopy(model)\n",
    "for tupl in split_tuples:\n",
    "    lname, rank, decomposition = layer_names[tupl], ranks[tupl], decompositions[tupl]\n",
    "    print(lname, rank)\n",
    "    compressed_model = get_compressed_model(compressed_model,\n",
    "                                            ranks=rank,\n",
    "                                            layer_names=lname,\n",
    "                                            decompositions = decomposition,\n",
    "                                            vbmf_weaken_factor=WEAKEN_FACTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (body): ResNet(\n",
       "    (stem): StemWithFixedBatchNorm(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d()\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): BottleneckWithFixedBatchNorm(\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): FrozenBatchNorm2d()\n",
       "        )\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): FrozenBatchNorm2d()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): FrozenBatchNorm2d()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): FrozenBatchNorm2d()\n",
       "      )\n",
       "      (1): BottleneckWithFixedBatchNorm(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): FrozenBatchNorm2d()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): FrozenBatchNorm2d()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): FrozenBatchNorm2d()\n",
       "      )\n",
       "      (2): BottleneckWithFixedBatchNorm(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): FrozenBatchNorm2d()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): FrozenBatchNorm2d()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): FrozenBatchNorm2d()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BottleneckWithFixedBatchNorm(\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): FrozenBatchNorm2d()\n",
       "        )\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (bn1): FrozenBatchNorm2d()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): FrozenBatchNorm2d()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): FrozenBatchNorm2d()\n",
       "      )\n",
       "      (1): BottleneckWithFixedBatchNorm(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): FrozenBatchNorm2d()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): FrozenBatchNorm2d()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): FrozenBatchNorm2d()\n",
       "      )\n",
       "      (2): BottleneckWithFixedBatchNorm(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): FrozenBatchNorm2d()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): FrozenBatchNorm2d()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): FrozenBatchNorm2d()\n",
       "      )\n",
       "      (3): BottleneckWithFixedBatchNorm(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): FrozenBatchNorm2d()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): FrozenBatchNorm2d()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): FrozenBatchNorm2d()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BottleneckWithFixedBatchNorm(\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): FrozenBatchNorm2d()\n",
       "        )\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (bn1): FrozenBatchNorm2d()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): FrozenBatchNorm2d()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): FrozenBatchNorm2d()\n",
       "      )\n",
       "      (1): BottleneckWithFixedBatchNorm(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): FrozenBatchNorm2d()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): FrozenBatchNorm2d()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): FrozenBatchNorm2d()\n",
       "      )\n",
       "      (2): BottleneckWithFixedBatchNorm(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): FrozenBatchNorm2d()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): FrozenBatchNorm2d()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): FrozenBatchNorm2d()\n",
       "      )\n",
       "      (3): BottleneckWithFixedBatchNorm(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): FrozenBatchNorm2d()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): FrozenBatchNorm2d()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): FrozenBatchNorm2d()\n",
       "      )\n",
       "      (4): BottleneckWithFixedBatchNorm(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): FrozenBatchNorm2d()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): FrozenBatchNorm2d()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): FrozenBatchNorm2d()\n",
       "      )\n",
       "      (5): BottleneckWithFixedBatchNorm(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): FrozenBatchNorm2d()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): FrozenBatchNorm2d()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): FrozenBatchNorm2d()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def count_params(model):\n",
    "    n_params = 0\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        n_params += param.numel()\n",
    "    return n_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_count_dict_m = count_params(model)\n",
    "params_count_dict_cm = count_params(compressed_model)\n",
    "\n",
    "params_count_dict_m / params_count_dict_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]),\n",
       " array([15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       " [array([], dtype=int64)]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute FLOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from model_utils import  compute_model_flops, \\\n",
    "get_input_shapes_vgg, get_input_shapes_resnet, \\\n",
    "get_input_shapes_faster_rcnn_vgg, get_input_shapes_faster_rcnn_resnet50\n",
    "\n",
    "device = 'cuda'\n",
    "x = torch.randn(1, 3, 224, 224).to(device)\n",
    "\n",
    "if MODEL_NAME == 'vgg16_imagenet':\n",
    "    input_shapes_dict = get_input_shapes_vgg(model, x)\n",
    "    input_shapes_dict_cm = get_input_shapes_vgg(compressed_model, x)\n",
    "elif MODEL_NAME in 'resnet50_imagenet':\n",
    "    input_shapes_dict = get_input_shapes_resnet(model, x, resnet_id = 50)\n",
    "    input_shapes_dict_cm = get_input_shapes_resnet(compressed_model, x, resnet_id = 50)\n",
    "elif MODEL_NAME == 'resnet18_imagenet':\n",
    "    input_shapes_dict = get_input_shapes_resnet(model, x, resnet_id = 18)\n",
    "    input_shapes_dict_cm = get_input_shapes_resnet(compressed_model, x, resnet_id = 18)\n",
    "elif MODEL_NAME == 'faster_rcnn_vgg16':\n",
    "    input_shapes_dict = get_input_shapes_faster_rcnn_vgg(model, x)\n",
    "elif MODEL_NAME == 'faster_rcnn_resnet50':\n",
    "    input_shapes_dict = get_input_shapes_faster_rcnn_resnet50(model, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'body.stem.conv1': torch.Size([1, 3, 224, 224]),\n",
       " 'body.layer1.0.conv1': torch.Size([1, 64, 56, 56]),\n",
       " 'body.layer1.0.conv2': torch.Size([1, 64, 56, 56]),\n",
       " 'body.layer1.0.conv3': torch.Size([1, 64, 56, 56]),\n",
       " 'body.layer1.0.downsample.0': torch.Size([1, 64, 56, 56]),\n",
       " 'body.layer1.1.conv1': torch.Size([1, 256, 56, 56]),\n",
       " 'body.layer1.1.conv2': torch.Size([1, 64, 56, 56]),\n",
       " 'body.layer1.1.conv3': torch.Size([1, 64, 56, 56]),\n",
       " 'body.layer1.2.conv1': torch.Size([1, 256, 56, 56]),\n",
       " 'body.layer1.2.conv2': torch.Size([1, 64, 56, 56]),\n",
       " 'body.layer1.2.conv3': torch.Size([1, 64, 56, 56]),\n",
       " 'body.layer2.0.conv1': torch.Size([1, 256, 56, 56]),\n",
       " 'body.layer2.0.conv2': torch.Size([1, 128, 28, 28]),\n",
       " 'body.layer2.0.conv3': torch.Size([1, 128, 28, 28]),\n",
       " 'body.layer2.0.downsample.0': torch.Size([1, 256, 56, 56]),\n",
       " 'body.layer2.1.conv1': torch.Size([1, 512, 28, 28]),\n",
       " 'body.layer2.1.conv2': torch.Size([1, 128, 28, 28]),\n",
       " 'body.layer2.1.conv3': torch.Size([1, 128, 28, 28]),\n",
       " 'body.layer2.2.conv1': torch.Size([1, 512, 28, 28]),\n",
       " 'body.layer2.2.conv2': torch.Size([1, 128, 28, 28]),\n",
       " 'body.layer2.2.conv3': torch.Size([1, 128, 28, 28]),\n",
       " 'body.layer2.3.conv1': torch.Size([1, 512, 28, 28]),\n",
       " 'body.layer2.3.conv2': torch.Size([1, 128, 28, 28]),\n",
       " 'body.layer2.3.conv3': torch.Size([1, 128, 28, 28]),\n",
       " 'body.layer3.0.conv1': torch.Size([1, 512, 28, 28]),\n",
       " 'body.layer3.0.conv2': torch.Size([1, 256, 14, 14]),\n",
       " 'body.layer3.0.conv3': torch.Size([1, 256, 14, 14]),\n",
       " 'body.layer3.0.downsample.0': torch.Size([1, 512, 28, 28]),\n",
       " 'body.layer3.1.conv1': torch.Size([1, 1024, 14, 14]),\n",
       " 'body.layer3.1.conv2': torch.Size([1, 256, 14, 14]),\n",
       " 'body.layer3.1.conv3': torch.Size([1, 256, 14, 14]),\n",
       " 'body.layer3.2.conv1': torch.Size([1, 1024, 14, 14]),\n",
       " 'body.layer3.2.conv2': torch.Size([1, 256, 14, 14]),\n",
       " 'body.layer3.2.conv3': torch.Size([1, 256, 14, 14]),\n",
       " 'body.layer3.3.conv1': torch.Size([1, 1024, 14, 14]),\n",
       " 'body.layer3.3.conv2': torch.Size([1, 256, 14, 14]),\n",
       " 'body.layer3.3.conv3': torch.Size([1, 256, 14, 14]),\n",
       " 'body.layer3.4.conv1': torch.Size([1, 1024, 14, 14]),\n",
       " 'body.layer3.4.conv2': torch.Size([1, 256, 14, 14]),\n",
       " 'body.layer3.4.conv3': torch.Size([1, 256, 14, 14]),\n",
       " 'body.layer3.5.conv1': torch.Size([1, 1024, 14, 14]),\n",
       " 'body.layer3.5.conv2': torch.Size([1, 256, 14, 14]),\n",
       " 'body.layer3.5.conv3': torch.Size([1, 256, 14, 14])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shapes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial model, conv: 15346630656(0.99), fc: 123633664(0.01)\n",
      "Compressed model, conv: 15346630656(0.99), fc: 123633664(0.01)\n",
      "\n",
      " FLOPS speed-up, conv: 1.0, total: 1.0\n",
      " FLOPS speed-up, fc: 1.0, total: 1.0\n"
     ]
    }
   ],
   "source": [
    "flops_m = compute_model_flops(model, input_shapes_dict)\n",
    "flops_cm = compute_model_flops(compressed_model, input_shapes_dict_cm)\n",
    "\n",
    "for flops, model_title in zip([flops_m, flops_cm],\n",
    "                              ['Initial model', 'Compressed model']):\n",
    "    print('{}, conv: {}({}), fc: {}({})'.format(model_title,\n",
    "                                                flops['conv'],\n",
    "                                                np.round(flops['conv']/sum(flops.values()), decimals = 2),\n",
    "                                                flops['fc'],\n",
    "                                                np.round(flops['fc']/sum(flops.values()), decimals = 2)))\n",
    "\n",
    "print('\\n FLOPS speed-up, conv: {}, total: {}'.format(flops_m['conv']/flops_cm['conv'],\n",
    "                                                   sum(flops_m.values())/sum(flops_cm.values())\n",
    "                                                  ))\n",
    "if flops_cm['fc'] > 0:\n",
    "    print(' FLOPS speed-up, fc: {}, total: {}'.format(flops_m['fc']/flops_cm['fc'],\n",
    "                                                      sum(flops_m.values())/sum(flops_cm.values())\n",
    "                                                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0 0.01\n",
      "features.2 0.12\n",
      "features.5 0.06\n",
      "features.7 0.12\n",
      "features.10 0.06\n",
      "features.12 0.12\n",
      "features.14 0.12\n",
      "features.17 0.06\n",
      "features.19 0.12\n",
      "features.21 0.12\n",
      "features.24 0.03\n",
      "features.26 0.03\n",
      "features.28 0.03\n",
      "classifier.0 0.01\n",
      "classifier.3 0.0\n",
      "classifier.6 0.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'conv': 15346630656, 'fc': 123633664}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_model_flops(compressed_model, input_shapes_dict_cm, verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
