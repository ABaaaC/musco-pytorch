{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from model_utils import load_model\n",
    "\n",
    "# MODEL_NAME = 'vgg16_imagenet'\n",
    "MODEL_NAME = 'resnet50_imagenet'\n",
    "# MODEL_NAME = 'resnet18_imagenet'\n",
    "\n",
    "# MODEL_NAME = 'faster_rcnn_vgg16\n",
    "# MODEL_NAME = 'faster_rcnn_resnet50'\n",
    "\n",
    "\n",
    "# # Uncomment if MODEL_NAME = 'faster_rcnn_resnet50'\n",
    "# sys.path.append('/workspace/home/jgusak/maxvol_objects/facebook_frcnn/')\n",
    "# import maskrcnn_benchmark\n",
    "\n",
    "model = load_model(MODEL_NAME)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get  all  layers\n",
    "\n",
    "Function  **get_layer_names()** returns names of model layers (convolutional and fully connected) and boolean mask for convolutional layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv1' 'layer1.0.conv1' 'layer1.0.conv2' 'layer1.0.conv3'\n",
      " 'layer1.0.downsample.0' 'layer1.1.conv1' 'layer1.1.conv2'\n",
      " 'layer1.1.conv3' 'layer1.2.conv1' 'layer1.2.conv2' 'layer1.2.conv3'\n",
      " 'layer2.0.conv1' 'layer2.0.conv2' 'layer2.0.conv3'\n",
      " 'layer2.0.downsample.0' 'layer2.1.conv1' 'layer2.1.conv2'\n",
      " 'layer2.1.conv3' 'layer2.2.conv1' 'layer2.2.conv2' 'layer2.2.conv3'\n",
      " 'layer2.3.conv1' 'layer2.3.conv2' 'layer2.3.conv3' 'layer3.0.conv1'\n",
      " 'layer3.0.conv2' 'layer3.0.conv3' 'layer3.0.downsample.0'\n",
      " 'layer3.1.conv1' 'layer3.1.conv2' 'layer3.1.conv3' 'layer3.2.conv1'\n",
      " 'layer3.2.conv2' 'layer3.2.conv3' 'layer3.3.conv1' 'layer3.3.conv2'\n",
      " 'layer3.3.conv3' 'layer3.4.conv1' 'layer3.4.conv2' 'layer3.4.conv3'\n",
      " 'layer3.5.conv1' 'layer3.5.conv2' 'layer3.5.conv3' 'layer4.0.conv1'\n",
      " 'layer4.0.conv2' 'layer4.0.conv3' 'layer4.0.downsample.0'\n",
      " 'layer4.1.conv1' 'layer4.1.conv2' 'layer4.1.conv3' 'layer4.2.conv1'\n",
      " 'layer4.2.conv2' 'layer4.2.conv3']\n",
      "['fc']\n"
     ]
    }
   ],
   "source": [
    "from model_utils import get_layer_names\n",
    "\n",
    "layer_names, conv_layer_mask = get_layer_names(model)\n",
    "\n",
    "fc_layer_mask = (1 - conv_layer_mask).astype(bool)\n",
    "\n",
    "print(layer_names[conv_layer_mask])\n",
    "print(layer_names[fc_layer_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary function\n",
    "import numpy as np\n",
    "def split_resnet_layers_by_blocks(lnames):\n",
    "    starts = ['body.stem.conv1'] + ['body.layer{}'.format(i) for i in range(1,5)]\n",
    "\n",
    "    start_idx = 0\n",
    "    blocks_idxs = []\n",
    "    layer_names_by_blocks = []\n",
    "\n",
    "    for s in starts:\n",
    "        curr_block =  [l for l in lnames if l.startswith(s)]\n",
    "        layer_names_by_blocks.append(curr_block)\n",
    "\n",
    "        blocks_idxs.append(np.arange(start_idx, start_idx+len(curr_block)))\n",
    "        start_idx += len(curr_block)\n",
    "\n",
    "    return blocks_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compress selected layers\n",
    "\n",
    "For **convolutional** layers\n",
    "- Set **decomposition**: 'tucker2', 'cp3' or 'cp4'\n",
    "- Set  decomposition **ranks** for convolutional layers (namely, ranks we use to decompose convolutional weight tensors). \n",
    "  - In Tucker2 case, for one layer \n",
    "      - If **rank = None**, the layer won't be decomposed.\n",
    "      - Elif **rank = 0**, then  VBMF method with **vbmf_weaken_factor**  will be used to select (rank_cout, rank_cin).\n",
    "      - Elif **rank = (-scalar) < 0**, then values (rank_cout, rank_cin) will be choosen as maximal values which allow **(sacalar x) layer parameter reduction**.\n",
    "      - Else **rank = tuple** and determines absolute ranks values (rank_cout, rank_cin)\n",
    "  - In CP case, rank for one layer is a scalar\n",
    "      - If **rank = None**, the layer won't be decomposed.\n",
    "      - Elif **rank = (-scalar) < 0** then value for rank will be choosen as maximal rank which allows **(sacalar x) layer parameter reduction**.\n",
    "      - Else **rank = scalar > 0** and determines absolute rank value.\n",
    "      \n",
    "For **fully connected** layers\n",
    "- Set **decomposition** = 'svd'\n",
    "- Set decomposition for linear layers (namely, ranks we use to factorize weight matrices)\n",
    "    - In SVD case, rank for one layer is a scalar\n",
    "      - If **rank = None**, the layer won't be decomposed.\n",
    "      - Elif **rank = 0**, then  VBMF method with **vbmf_weaken_factor**  will be used to select rank.\n",
    "      - Elif **rank = (-scalar) < 0** then value for rank will be choosen as maximal rank which allows **(sacalar x) layer parameter reduction**.\n",
    "      - Else **rank = scalar > 0** and determines absolute rank value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor_compression import get_compressed_model\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "# decomposition_conv = 'cp4'\n",
    "decomposition_conv = 'cp3'\n",
    "# decomposition_conv = 'tucker2'\n",
    "\n",
    "decomposition_fc = 'svd'\n",
    "\n",
    "# RANK_SELECTION = 'vbmf'\n",
    "RANK_SELECTION = 'nx'\n",
    "# RANK_SELECTION = 'custom'\n",
    "\n",
    "if RANK_SELECTION == 'vbmf':\n",
    "    WEAKEN_FACTOR = 1.\n",
    "    X_FACTOR = 0\n",
    "    rank_selection_suffix = \"/wf:{}\".format(WEAKEN_FACTOR)\n",
    "elif RANK_SELECTION == 'nx':\n",
    "    WEAKEN_FACTOR = None  \n",
    "    X_FACTOR = 40\n",
    "    rank_selection_suffix = \"/{}x\".format(X_FACTOR)\n",
    "    \n",
    "    \n",
    "if MODEL_NAME == 'vgg16_imagenet':\n",
    "    ranks_conv = [None] + [-X_FACTOR]*(len(layer_names[conv_layer_mask])-1)\n",
    "    ranks_fc = [-X_FACTOR]*(len(layer_names[fc_layer_mask]))\n",
    "elif MODEL_NAME == 'resnet50_imagenet':\n",
    "    ranks_conv = [None if not name.endswith('conv2') else -X_FACTOR\n",
    "                  for name in layer_names[conv_layer_mask]]\n",
    "    ranks_fc = [-X_FACTOR]*(len(layer_names[fc_layer_mask]))\n",
    "elif MODEL_NAME == 'resnet18_imagenet':\n",
    "    ranks_conv = [None if name == 'conv1' or not (name.endswith('conv2') or\n",
    "                                                  name.endswith('conv1')) else -X_FACTOR\n",
    "              for name in layer_names[conv_layer_mask]]\n",
    "    ranks_fc = [-X_FACTOR]*(len(layer_names[fc_layer_mask]))\n",
    "elif MODEL_NAME ==  'faster_rcnn_resnet50':\n",
    "    ranks_conv = [None if not name.endswith('body.conv2') else -X_FACTOR\n",
    "                  for name in layer_names[conv_layer_mask]]\n",
    "    ranks_fc = [-X_FACTOR]*(len(layer_names[fc_layer_mask]))\n",
    "    \n",
    "    \n",
    "\n",
    "ranks = np.array([None]*len(layer_names))\n",
    "ranks[conv_layer_mask] = ranks_conv\n",
    "ranks[fc_layer_mask] = ranks_fc\n",
    "\n",
    "decompositions = np.array([None]*len(layer_names))\n",
    "decompositions[conv_layer_mask] = decomposition_conv\n",
    "decompositions[fc_layer_mask] = decomposition_fc\n",
    "\n",
    "CONV_SPLIT = 3\n",
    "FC_SPLIT = 1\n",
    "n_layers = len(layer_names)\n",
    "\n",
    "RESNET_SPLIT = False\n",
    "if MODEL_NAME in ['resnet50_imagenet', 'resnet18_imagenet',  'faster_rcnn_resnet50'] and RESNET_SPLIT:\n",
    "    split_tuples = split_resnet_layers_by_blocks(layer_names[conv_layer_mask])[::-1]\n",
    "else:\n",
    "    split_tuples = np.array_split(np.arange(n_layers)[conv_layer_mask], CONV_SPLIT)[::-1]\n",
    "split_tuples.append(np.array_split(np.arange(n_layers)[fc_layer_mask], FC_SPLIT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52]),\n",
       " array([18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "        35]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17]),\n",
       " [array([53])]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['layer3.3.conv3' 'layer3.4.conv1' 'layer3.4.conv2' 'layer3.4.conv3'\n",
      " 'layer3.5.conv1' 'layer3.5.conv2' 'layer3.5.conv3' 'layer4.0.conv1'\n",
      " 'layer4.0.conv2' 'layer4.0.conv3' 'layer4.0.downsample.0'\n",
      " 'layer4.1.conv1' 'layer4.1.conv2' 'layer4.1.conv3' 'layer4.2.conv1'\n",
      " 'layer4.2.conv2' 'layer4.2.conv3'] [None None -40 None None -40 None None -40 None None None -40 None None\n",
      " -40 None]\n",
      "Skip layer layer3.3.conv3\n",
      "Skip layer layer3.4.conv1\n",
      "Decompose layer layer3.4.conv2\n",
      "\t new rank:  28\n",
      "Skip layer layer3.4.conv3\n",
      "Skip layer layer3.5.conv1\n",
      "Decompose layer layer3.5.conv2\n",
      "\t new rank:  28\n",
      "Skip layer layer3.5.conv3\n",
      "Skip layer layer4.0.conv1\n",
      "Decompose layer layer4.0.conv2\n",
      "\t new rank:  57\n",
      "Skip layer layer4.0.conv3\n",
      "Skip layer layer4.0.downsample.0\n",
      "Skip layer layer4.1.conv1\n",
      "Decompose layer layer4.1.conv2\n",
      "\t new rank:  57\n",
      "Skip layer layer4.1.conv3\n",
      "Skip layer layer4.2.conv1\n",
      "Decompose layer layer4.2.conv2\n",
      "\t new rank:  57\n",
      "Skip layer layer4.2.conv3\n",
      "['layer2.2.conv1' 'layer2.2.conv2' 'layer2.2.conv3' 'layer2.3.conv1'\n",
      " 'layer2.3.conv2' 'layer2.3.conv3' 'layer3.0.conv1' 'layer3.0.conv2'\n",
      " 'layer3.0.conv3' 'layer3.0.downsample.0' 'layer3.1.conv1'\n",
      " 'layer3.1.conv2' 'layer3.1.conv3' 'layer3.2.conv1' 'layer3.2.conv2'\n",
      " 'layer3.2.conv3' 'layer3.3.conv1' 'layer3.3.conv2'] [None -40 None None -40 None None -40 None None None -40 None None -40\n",
      " None None -40]\n",
      "Skip layer layer2.2.conv1\n",
      "Decompose layer layer2.2.conv2\n",
      "\t new rank:  13\n",
      "Skip layer layer2.2.conv3\n",
      "Skip layer layer2.3.conv1\n",
      "Decompose layer layer2.3.conv2\n",
      "\t new rank:  13\n",
      "Skip layer layer2.3.conv3\n",
      "Skip layer layer3.0.conv1\n",
      "Decompose layer layer3.0.conv2\n",
      "\t new rank:  28\n",
      "Skip layer layer3.0.conv3\n",
      "Skip layer layer3.0.downsample.0\n",
      "Skip layer layer3.1.conv1\n",
      "Decompose layer layer3.1.conv2\n",
      "\t new rank:  28\n",
      "Skip layer layer3.1.conv3\n",
      "Skip layer layer3.2.conv1\n",
      "Decompose layer layer3.2.conv2\n",
      "\t new rank:  28\n",
      "Skip layer layer3.2.conv3\n",
      "Skip layer layer3.3.conv1\n",
      "Decompose layer layer3.3.conv2\n",
      "\t new rank:  28\n",
      "['conv1' 'layer1.0.conv1' 'layer1.0.conv2' 'layer1.0.conv3'\n",
      " 'layer1.0.downsample.0' 'layer1.1.conv1' 'layer1.1.conv2'\n",
      " 'layer1.1.conv3' 'layer1.2.conv1' 'layer1.2.conv2' 'layer1.2.conv3'\n",
      " 'layer2.0.conv1' 'layer2.0.conv2' 'layer2.0.conv3'\n",
      " 'layer2.0.downsample.0' 'layer2.1.conv1' 'layer2.1.conv2'\n",
      " 'layer2.1.conv3'] [None None -40 None None None -40 None None -40 None None -40 None None\n",
      " None -40 None]\n",
      "Skip layer conv1\n",
      "Skip layer layer1.0.conv1\n",
      "Decompose layer layer1.0.conv2\n",
      "\t new rank:  6\n",
      "Skip layer layer1.0.conv3\n",
      "Skip layer layer1.0.downsample.0\n",
      "Skip layer layer1.1.conv1\n",
      "Decompose layer layer1.1.conv2\n",
      "\t new rank:  6\n",
      "Skip layer layer1.1.conv3\n",
      "Skip layer layer1.2.conv1\n",
      "Decompose layer layer1.2.conv2\n",
      "\t new rank:  6\n",
      "Skip layer layer1.2.conv3\n",
      "Skip layer layer2.0.conv1\n",
      "Decompose layer layer2.0.conv2\n",
      "\t new rank:  13\n",
      "Skip layer layer2.0.conv3\n",
      "Skip layer layer2.0.downsample.0\n",
      "Skip layer layer2.1.conv1\n",
      "Decompose layer layer2.1.conv2\n",
      "\t new rank:  13\n",
      "Skip layer layer2.1.conv3\n",
      "['fc'] [-40]\n",
      "Decompose layer fc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t new rank:  16\n"
     ]
    }
   ],
   "source": [
    "compressed_model = copy.deepcopy(model)\n",
    "for tupl in split_tuples:\n",
    "    lname, rank, decomposition = layer_names[tupl], ranks[tupl], decompositions[tupl]\n",
    "    print(lname, rank)\n",
    "    compressed_model = get_compressed_model(compressed_model,\n",
    "                                            ranks=rank,\n",
    "                                            layer_names=lname,\n",
    "                                            decompositions = decomposition,\n",
    "                                            vbmf_weaken_factor=WEAKEN_FACTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(64, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
       "        (conv2-2): Conv2d(6, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(64, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
       "        (conv2-2): Conv2d(6, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(64, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
       "        (conv2-2): Conv2d(6, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(128, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(13, 13, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=13, bias=False)\n",
       "        (conv2-2): Conv2d(13, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(128, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(13, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=13, bias=False)\n",
       "        (conv2-2): Conv2d(13, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(128, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(13, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=13, bias=False)\n",
       "        (conv2-2): Conv2d(13, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(128, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(13, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=13, bias=False)\n",
       "        (conv2-2): Conv2d(13, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(256, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(28, 28, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=28, bias=False)\n",
       "        (conv2-2): Conv2d(28, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(256, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=28, bias=False)\n",
       "        (conv2-2): Conv2d(28, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(256, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=28, bias=False)\n",
       "        (conv2-2): Conv2d(28, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(256, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=28, bias=False)\n",
       "        (conv2-2): Conv2d(28, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(256, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=28, bias=False)\n",
       "        (conv2-2): Conv2d(28, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(256, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=28, bias=False)\n",
       "        (conv2-2): Conv2d(28, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(512, 57, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(57, 57, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=57, bias=False)\n",
       "        (conv2-2): Conv2d(57, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(512, 57, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(57, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=57, bias=False)\n",
       "        (conv2-2): Conv2d(57, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(512, 57, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(57, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=57, bias=False)\n",
       "        (conv2-2): Conv2d(57, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Sequential(\n",
       "    (fc-0): Linear(in_features=2048, out_features=16, bias=False)\n",
       "    (fc-1): Linear(in_features=16, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def count_params(model):\n",
    "    n_params = 0\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        n_params += param.numel()\n",
    "    return n_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0411385093278325"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_count_dict_m = count_params(model)\n",
    "params_count_dict_cm = count_params(compressed_model)\n",
    "\n",
    "params_count_dict_m / params_count_dict_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52]),\n",
       " array([18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "        35]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17]),\n",
       " [array([53])]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute FLOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compressed_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from flopco import FlopCo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "flopco_m = FlopCo(model)\n",
    "flopco_cm = FlopCo(compressed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.782351684812708"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flopco_m.total_flops / flopco_cm.total_flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'conv1': [236027904],\n",
       "             'layer1.0.conv1': [25690112],\n",
       "             'layer1.0.conv2': [231211008],\n",
       "             'layer1.0.conv3': [102760448],\n",
       "             'layer1.0.downsample.0': [102760448],\n",
       "             'layer1.1.conv1': [102760448],\n",
       "             'layer1.1.conv2': [231211008],\n",
       "             'layer1.1.conv3': [102760448],\n",
       "             'layer1.2.conv1': [102760448],\n",
       "             'layer1.2.conv2': [231211008],\n",
       "             'layer1.2.conv3': [102760448],\n",
       "             'layer2.0.conv1': [205520896],\n",
       "             'layer2.0.conv2': [231211008],\n",
       "             'layer2.0.conv3': [102760448],\n",
       "             'layer2.0.downsample.0': [205520896],\n",
       "             'layer2.1.conv1': [102760448],\n",
       "             'layer2.1.conv2': [231211008],\n",
       "             'layer2.1.conv3': [102760448],\n",
       "             'layer2.2.conv1': [102760448],\n",
       "             'layer2.2.conv2': [231211008],\n",
       "             'layer2.2.conv3': [102760448],\n",
       "             'layer2.3.conv1': [102760448],\n",
       "             'layer2.3.conv2': [231211008],\n",
       "             'layer2.3.conv3': [102760448],\n",
       "             'layer3.0.conv1': [205520896],\n",
       "             'layer3.0.conv2': [231211008],\n",
       "             'layer3.0.conv3': [102760448],\n",
       "             'layer3.0.downsample.0': [205520896],\n",
       "             'layer3.1.conv1': [102760448],\n",
       "             'layer3.1.conv2': [231211008],\n",
       "             'layer3.1.conv3': [102760448],\n",
       "             'layer3.2.conv1': [102760448],\n",
       "             'layer3.2.conv2': [231211008],\n",
       "             'layer3.2.conv3': [102760448],\n",
       "             'layer3.3.conv1': [102760448],\n",
       "             'layer3.3.conv2': [231211008],\n",
       "             'layer3.3.conv3': [102760448],\n",
       "             'layer3.4.conv1': [102760448],\n",
       "             'layer3.4.conv2': [231211008],\n",
       "             'layer3.4.conv3': [102760448],\n",
       "             'layer3.5.conv1': [102760448],\n",
       "             'layer3.5.conv2': [231211008],\n",
       "             'layer3.5.conv3': [102760448],\n",
       "             'layer4.0.conv1': [205520896],\n",
       "             'layer4.0.conv2': [231211008],\n",
       "             'layer4.0.conv3': [102760448],\n",
       "             'layer4.0.downsample.0': [205520896],\n",
       "             'layer4.1.conv1': [102760448],\n",
       "             'layer4.1.conv2': [231211008],\n",
       "             'layer4.1.conv3': [102760448],\n",
       "             'layer4.2.conv1': [102760448],\n",
       "             'layer4.2.conv2': [231211008],\n",
       "             'layer4.2.conv3': [102760448],\n",
       "             'fc': [4096000]})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flopco_m.flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
